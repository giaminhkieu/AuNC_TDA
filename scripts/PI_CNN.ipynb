{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0CdEEiyG2GJ"
      },
      "source": [
        "# Generating Persistence Images and Simplical complex features to predict AuNC properties\n",
        "\n",
        "1. This notebook focuses on generating persistence images and simplicial complex count and using them to build a Kernel Ridge Regression and Random Forest Regression model to predict the HOMO-LUMO gap, internal energies, and dipole moment of AuNCs.\n",
        "2. Persistence Images were generated using the code in Townsend *et. al.* 2020 publication, publicly available at: https://gitlab.com/voglab/PersistentImages_Chemistry\n",
        "3. Simplex analysis were done using GUDHI package\n",
        "4. Please make sure that this notebook is in the same directory as the data folder and the scripts:\n",
        "> 1. ElementsInfo.py\n",
        "> 2. PersistentImageCode.py\n",
        "> 3. VariancePersistCode.py\n",
        "> 4. GenerateImagePI.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki4_nk4hFq0F"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXKRJ4SdVsQP",
        "outputId": "6bd72d8a-c542-4b7b-b830-bee7827ad53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gudhi\n",
            "  Downloading gudhi-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from gudhi) (1.23.5)\n",
            "Installing collected packages: gudhi\n",
            "Successfully installed gudhi-3.8.0\n",
            "Collecting ripser\n",
            "  Downloading ripser-0.6.4.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from ripser) (0.29.36)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ripser) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ripser) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ripser) (1.2.2)\n",
            "Collecting persim (from ripser)\n",
            "  Downloading persim-0.3.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from persim->ripser) (3.7.1)\n",
            "Collecting hopcroftkarp (from persim->ripser)\n",
            "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated (from persim->ripser)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from persim->ripser) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ripser) (3.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->persim->ripser) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->persim->ripser) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->persim->ripser) (1.16.0)\n",
            "Building wheels for collected packages: ripser, hopcroftkarp\n",
            "  Building wheel for ripser (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ripser: filename=ripser-0.6.4-cp310-cp310-linux_x86_64.whl size=752978 sha256=c316e2cfaad2d0074a37a702b974119b905c4de95176f8fb7dc9cb2c37ea5620\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/f5/66/f41f708b049057431155934f74e20ca6001a085fcd2e615150\n",
            "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18103 sha256=a7cec3079b30d592b12cf002653e0b49cccab92db8d54b13fd72310d52630f17\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/0f/3b/0f931844eecc34addd90e72d54cd39c08b7066c5f25c00b9a4\n",
            "Successfully built ripser hopcroftkarp\n",
            "Installing collected packages: hopcroftkarp, deprecated, persim, ripser\n",
            "Successfully installed deprecated-1.2.14 hopcroftkarp-1.2.5 persim-0.3.1 ripser-0.6.4\n",
            "Collecting elements\n",
            "  Downloading elements-1.0.0.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from elements) (1.23.5)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from elements) (2.31.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->elements) (9.4.0)\n",
            "Building wheels for collected packages: elements\n",
            "  Building wheel for elements (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elements: filename=elements-1.0.0-py3-none-any.whl size=21892 sha256=5707a5424e52e7b9db154911a204448f1c74fdee4a77374261a18b8f25513d99\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/b2/1d/b417ced7c50363975f73c922903470bb743dfe21f97051353f\n",
            "Successfully built elements\n",
            "Installing collected packages: elements\n",
            "Successfully installed elements-1.0.0\n",
            "Collecting qml\n",
            "  Downloading qml-0.4.0.27.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: qml\n",
            "  Building wheel for qml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qml: filename=qml-0.4.0.27-cp310-cp310-linux_x86_64.whl size=1211678 sha256=1578e910d3a447223f156204ced69156cd725aa4664a22d863c954316812ad2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/57/2f/cdd885bb28ee050be4f41882d74d716e1fc0ff0745a657b39a\n",
            "Successfully built qml\n",
            "Installing collected packages: qml\n",
            "Successfully installed qml-0.4.0.27\n",
            "Collecting dscribe\n",
            "  Downloading dscribe-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.4 (from dscribe)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dscribe) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dscribe) (1.10.1)\n",
            "Collecting ase>=3.19.0 (from dscribe)\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from dscribe) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from dscribe) (1.3.2)\n",
            "Collecting sparse (from dscribe)\n",
            "  Downloading sparse-0.14.0-py2.py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase>=3.19.0->dscribe) (3.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dscribe) (3.2.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from sparse->dscribe) (0.56.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase>=3.19.0->dscribe) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->sparse->dscribe) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->sparse->dscribe) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase>=3.19.0->dscribe) (1.16.0)\n",
            "Installing collected packages: pybind11, sparse, ase, dscribe\n",
            "Successfully installed ase-3.22.1 dscribe-2.0.1 pybind11-2.11.1 sparse-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gudhi\n",
        "!pip install ripser\n",
        "!pip install elements\n",
        "!pip install qml\n",
        "!pip install dscribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZB4QckCd5bA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import qml\n",
        "from qml.representations import *\n",
        "from natsort import natsorted\n",
        "from dscribe.descriptors import SOAP\n",
        "from ase.io import read\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcP4hneFh24"
      },
      "source": [
        "# Process data and store them to pickle files\n",
        "Note: CM and SOAP features are too large to be stored within pickle files. The current pickle file uploaded in the \"data\" directory does not contain CM and SOAP feature vectors, and they must be calculated in the corresponding code blocks below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlkMTF4K1eyZ"
      },
      "outputs": [],
      "source": [
        "# import dataframe\n",
        "DatasetAuNC = pd.read_excel(\"./data/AuNC/DatasetAuNC.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3zc5WFR2X8B"
      },
      "outputs": [],
      "source": [
        "# Appending xyz\n",
        "\n",
        "os.chdir('./data/AuNC/AuNC_xyz_files')\n",
        "\n",
        "xyz_list = []\n",
        "files = []\n",
        "for i in tqdm(range(len(DatasetAuNC))):\n",
        "    try:\n",
        "        xyz_filename = DatasetAuNC[\"Filename\"][i] + \".xyz\"\n",
        "        with open(xyz_filename) as f:\n",
        "            lines = f.readlines()\n",
        "            files.append(xyz_filename)\n",
        "            xyz_list.append(lines)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{xyz_filename}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error at index {i}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "DatasetAuNC[\"xyz\"] = xyz_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JQVzTqV_UX9"
      },
      "outputs": [],
      "source": [
        "# Calculating Betti feature count for overview\n",
        "\n",
        "Error = []\n",
        "B0_list = []\n",
        "B1_list = []\n",
        "B2_list = []\n",
        "\n",
        "for i in range(len(DatasetAuNC)):\n",
        "  try:\n",
        "    D, elements = Makexyzdistance(DatasetAuNC[\"xyz\"][i])\n",
        "    persistent_homology_features = ripser(D,distance_matrix=True, maxdim = 2)\n",
        "    B0_list.append(len(persistent_homology_features['dgms'][0])-1)\n",
        "    B1_list.append(len(persistent_homology_features['dgms'][1]))\n",
        "    B2_list.append(len(persistent_homology_features['dgms'][2]))\n",
        "\n",
        "  except:\n",
        "    Error.append(DatasetAuNC[\"Number\"][i])\n",
        "    continue\n",
        "\n",
        "DatasetAuNC[\"Betti0count\"] = B0_list\n",
        "DatasetAuNC[\"Betti1count\"] = B1_list\n",
        "DatasetAuNC[\"Betti2count\"] = B2_list\n",
        "\n",
        "print(\"Finished appending Betti feature count!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1T4Cxhe7QYq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Calculating and appending VariancePersist arrays to pandas dataframe\n",
        "VariancePersistv1 is a modified PI function with added buffer values\n",
        "(0.5, 0.05) for Betti 1 and 2 features.\n",
        "Except block is added due to some xyz file having values written in different notations (e.g. 1e-4)\n",
        "and cannot be read as a float. (current AuNC database does not have this issue)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def append_persistence_image(Dataframe):\n",
        "  Error = []\n",
        "  PersImgArr = []\n",
        "\n",
        "  for idx in range(len(Dataframe)):\n",
        "    try:\n",
        "        persistent_image_matrix = VariancePersistv1(\n",
        "                              Dataframe[\"xyz\"][idx],\n",
        "                              pixelx=resolution,\n",
        "                              pixely=resolution,\n",
        "                              myspread=myspread ,\n",
        "                              myspecs={\"maxBD\": max_bound, \"minBD\":min_bound},\n",
        "                              electroneg_addition=electroneg_addition,\n",
        "                              electroneg_division=electroneg_division,\n",
        "                              B1_buffer=B1_buffer,\n",
        "                              B2_buffer=B2_buffer,\n",
        "                              showplot = False\n",
        "                              )\n",
        "\n",
        "        PersImgArr.append(persistent_image_matrix)\n",
        "    except:\n",
        "        Error.append(idx)\n",
        "        print(\"Error at index: \", idx)\n",
        "        PersImgArr.append(np.zeros(resolution*resolution,))\n",
        "\n",
        "  Dataframe[\"PersImg\"] = PersImgArr\n",
        "  print(\"Finished appending Persistence Images!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Persistence Image Parameters\n",
        "resolution=100\n",
        "myspread=0.3\n",
        "min_bound=-0.3\n",
        "max_bound=7\n",
        "electroneg_addition=+0.4\n",
        "electroneg_division=10\n",
        "B1_buffer=0.5\n",
        "B2_buffer=0.05\n",
        "\n",
        "append_persistence_image(DatasetAuNC)"
      ],
      "metadata": {
        "id": "19TJqyHm6n6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGVd8emwtP1Y"
      },
      "outputs": [],
      "source": [
        "# Simplcial complex analysis\n",
        "def Simplex_analyze(Core_coordinates, bond_length_limit):\n",
        "  rips= gudhi.RipsComplex(points=list(Core_coordinates), max_edge_length=10.0)\n",
        "  simplex_tree = rips.create_simplex_tree(max_dimension=3)\n",
        "  simplex_generator = simplex_tree.get_skeleton(3)\n",
        "\n",
        "  Tetrahedra_list = []\n",
        "  Vertices_of_tetrahedra = []\n",
        "  Overlapping_triangles = []\n",
        "  Unconnected_triangles = []\n",
        "  Triangles_with_1_shared_vertex = []\n",
        "  Triangles_with_2_shared_vertices = []\n",
        "\n",
        "  for simplex in simplex_generator:\n",
        "    if simplex[1] >= bond_length_limit: continue\n",
        "    if len(simplex[0]) == 4: #simplex[0]: list of vertices, simplex[1]: birth filtration\n",
        "      Tetrahedra_list.append(simplex)\n",
        "      for vertex in simplex[0]:\n",
        "        if vertex not in Vertices_of_tetrahedra:\n",
        "          Vertices_of_tetrahedra.append(vertex)\n",
        "\n",
        "  rips= gudhi.RipsComplex(points=list(Core_coordinates), max_edge_length=10.0)\n",
        "  simplex_tree = rips.create_simplex_tree(max_dimension=3)\n",
        "  simplex_generator = simplex_tree.get_skeleton(3)\n",
        "\n",
        "  for simplex in simplex_generator:\n",
        "    Shared_count_arr = []\n",
        "\n",
        "    if simplex[1] >= bond_length_limit: continue\n",
        "    if len(simplex[0]) != 3: continue\n",
        "\n",
        "    if len(Tetrahedra_list) == 0: Unconnected_triangles.append(simplex[0])\n",
        "    else:\n",
        "      for tetrahedra in Tetrahedra_list:\n",
        "        Shared_count_arr.append(len(set(simplex[0]) & set(tetrahedra[0])))\n",
        "\n",
        "      if max(Shared_count_arr) == 3: Overlapping_triangles.append(simplex)\n",
        "      elif max(Shared_count_arr) == 2: Triangles_with_2_shared_vertices.append(simplex)\n",
        "      elif max(Shared_count_arr) == 1: Triangles_with_1_shared_vertex.append(simplex)\n",
        "      else: Unconnected_triangles.append(simplex)\n",
        "\n",
        "  return {\"Tetrahedral_count\": len(Tetrahedra_list), \"Unconnected_triangles_count\": len(Unconnected_triangles),\n",
        "          \"Triangles_with_1_shared_vertex_count\":len(Triangles_with_1_shared_vertex),\n",
        "          \"Triangles_with_2_shared_vertices_count\": len(Triangles_with_2_shared_vertices)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RZhjH8ethJo"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Simplex analysis\n",
        "\"\"\"\n",
        "os.chdir('./data/AuNC/AuNC_xyz_files')\n",
        "Tetrahedral_count_arr = []\n",
        "Unconnected_triangles_count_arr = []\n",
        "Triangles_with_1_shared_vertex_count_arr = []\n",
        "Triangles_with_2_shared_vertices_count_arr = []\n",
        "files = []\n",
        "\n",
        "for idx in range(len(DatasetAuNC)):\n",
        "  try:\n",
        "    filename = DatasetAuNC[\"Filename\"][idx] + \".xyz\"\n",
        "    df=pd.read_table(filename, delim_whitespace=True, names=['a','b','c','d'],skiprows = 2) # skip the first 2 lines of xyz files\n",
        "    mat = df[['b','c','d']].to_numpy()\n",
        "    ElementArr = df['a'].to_numpy()\n",
        "\n",
        "    Core_coordinates = []\n",
        "\n",
        "    for index in range(len(ElementArr)):\n",
        "      if ElementArr[index] != \"Au\": continue\n",
        "      Core_coordinates.append(mat[index])\n",
        "\n",
        "    Dict = Simplex_analyze(Core_coordinates, bond_length_limit = 4.0)\n",
        "\n",
        "    Tetrahedral_count_arr.append(Dict[\"Tetrahedral_count\"])\n",
        "    Unconnected_triangles_count_arr.append(Dict[\"Unconnected_triangles_count\"])\n",
        "    Triangles_with_1_shared_vertex_count_arr.append(Dict[\"Triangles_with_1_shared_vertex_count\"])\n",
        "    Triangles_with_2_shared_vertices_count_arr.append(Dict[\"Triangles_with_2_shared_vertices_count\"])\n",
        "\n",
        "    print(\"Done: \", idx)\n",
        "    print(len(Tetrahedral_count_arr))\n",
        "\n",
        "\n",
        "  except:\n",
        "    print(\"error at: \", idx)\n",
        "    continue\n",
        "\n",
        "DatasetAuNC[\"Tetrahedral_count\"] = Tetrahedral_count_arr\n",
        "DatasetAuNC[\"Unconnected_triangles_count\"] = Unconnected_triangles_count_arr\n",
        "DatasetAuNC[\"Triangles_with_1_shared_vertex_count\"] = Triangles_with_1_shared_vertex_count_arr\n",
        "DatasetAuNC[\"Triangles_with_2_shared_vertices_count\"] = Triangles_with_2_shared_vertices_count_arr\n",
        "\n",
        "print(\"Finished appending Simplex count!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Calculating and appending Coulomb Matrix arrays to pandas dataframe\n",
        "\"\"\"\n",
        "def append_cm(dataframe, xyz_root):\n",
        "  CoulMatArr = []\n",
        "  for f in natsorted(os.listdir(xyz_root)):\n",
        "    try:\n",
        "      mol = qml.Compound(xyz=f)\n",
        "      mol.generate_coulomb_matrix(size=2000, sorting=\"row-norm\")\n",
        "      A = mol.representation\n",
        "      CoulMatArr.append([f,A])\n",
        "    except:\n",
        "      print(\"Error at: \", f)\n",
        "\n",
        "  # Sample array containing the format [\"Filename.xyz\", property array]\n",
        "  property_arrays = np.empty(len(dataframe), dtype=object)\n",
        "\n",
        "  for filename, property_array in CoulMatArr:\n",
        "      filename_without_extension = filename.split('.xyz')[0]\n",
        "      row_index = dataframe.index[dataframe['Filename'] == filename_without_extension]\n",
        "\n",
        "      if len(row_index) == 1:\n",
        "          property_arrays[row_index[0]] = property_array\n",
        "      else:\n",
        "          print(f\"Filename '{filename_without_extension}' not found in the DataFrame.\")\n",
        "\n",
        "  dataframe['Coulomb_Matrix'] = property_arrays\n",
        "  print(\"Finished appending Coulomb Matrices!\")\n",
        "\n",
        "append_cm(DatasetAuNC, \"./data/AuNC/AuNC_xyz_files\")"
      ],
      "metadata": {
        "id": "qBW1TrJRKmos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Calculating and appending SOAP arrays to pandas dataframe\n",
        "\"\"\"\n",
        "def append_soap(dataframe, xyz_root):\n",
        "  species = [\"Au\", \"P\", \"S\", \"Sb\", \"Se\", \"Cl\", \"Br\", \"F\", \"C\", \"N\", \"O\", \"H\", \"I\", \"Fe\"]\n",
        "  r_cut = 6.0\n",
        "  n_max = 8\n",
        "  l_max = 6\n",
        "\n",
        "  soap = SOAP(\n",
        "      species=species,\n",
        "      periodic=False,\n",
        "      r_cut=r_cut,\n",
        "      n_max=n_max,\n",
        "      l_max=l_max,\n",
        "  )\n",
        "\n",
        "  SOAPArr = []\n",
        "  for f in natsorted(os.listdir(xyz_root)):\n",
        "    try:\n",
        "      mol = read(f)\n",
        "      a = soap.create(system=mol,centers=[0])\n",
        "      A = a.flatten()\n",
        "      SOAPArr.append([f,A])\n",
        "    except:\n",
        "      print(\"error at: \", f)\n",
        "\n",
        "  property_arrays = np.empty(len(dataframe), dtype=object)\n",
        "\n",
        "  for filename, property_array in SOAPArr:\n",
        "      filename_without_extension = filename.split('.xyz')[0]\n",
        "      row_index = dataframe.index[dataframe['Filename'] == filename_without_extension]\n",
        "\n",
        "      if len(row_index) == 1:\n",
        "          property_arrays[row_index[0]] = property_array\n",
        "      else:\n",
        "          print(f\"Filename '{filename_without_extension}' not found in the DataFrame.\")\n",
        "\n",
        "  dataframe['SOAP'] = property_arrays\n",
        "  print(\"Finished appending SOAP!\")\n",
        "\n",
        "append_soap(DatasetAuNC, \"./data/AuNC/AuNC_xyz_files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unxheweybkcO",
        "outputId": "bd22f611-e31f-43e4-b77e-c9d55c70a00f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done:  Au2_PET_PPh3_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au2_SbTol3_2_Cl2_c0.xyz shape:  (44296,)\n",
            "Done:  Au3_iylidene_3_c1.xyz shape:  (44296,)\n",
            "Done:  Au3_pylidene_2_PPh3_c1.xyz shape:  (44296,)\n",
            "Done:  Au4_PPh2an_4_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au4_PPh3_4_Br2_c2.xyz shape:  (44296,)\n",
            "Done:  Au4_PPh3_4_I2_c0.xyz shape:  (44296,)\n",
            "Done:  Au4_PPh3_4_I2_c2.xyz shape:  (44296,)\n",
            "Done:  Au4_STol_2_PPh3_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au4_dppm_3_I2_c0.xyz shape:  (44296,)\n",
            "Done:  Au5_P_PPh3_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au5_dppm_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_C_PPh2pyr_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_C_bylidene_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_PPh3_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_PXant_3_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_PhDP_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_S2Tol_6_c0.xyz shape:  (44296,)\n",
            "Done:  Au6_Se2_dppNPh_3_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_Se2_dppNR4_3_c2.xyz shape:  (44296,)\n",
            "Done:  Au6_dppp_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au7_PPh3_7_c1.xyz shape:  (44296,)\n",
            "Done:  Au7_dppp_4_c3.xyz shape:  (44296,)\n",
            "Done:  Au8_PPh3_7_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_Pmet3_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_S2_dppm_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppf_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_CCBu_2_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_CCCCPh_2_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_CCPh_2_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_SPyH_2_c4.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_SPy_2_c2.xyz shape:  (44296,)\n",
            "Done:  Au8_dppp_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au9_PNC_6_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_PPh3_8_C4_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_PPh3_8_D2h_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_PPh3_8_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_Pan3_8_C4_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_Pan3_8_D2h_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_R-BINAP_4_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_S-BINAP_4_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_dpph_4_db_c3.xyz shape:  (44296,)\n",
            "Done:  Au9_dpph_4_dc_c3.xyz shape:  (44296,)\n",
            "Done:  Au10_PCy2Ph_6_Cl3_c1.xyz shape:  (44296,)\n",
            "Done:  Au10_PPh3_5_C6F5_4_c0.xyz shape:  (44296,)\n",
            "Done:  Au10_PPh3_7_S2C2CN2_2_c0.xyz shape:  (44296,)\n",
            "Done:  Au10_PPh3_8_NCO_Cl_c0.xyz shape:  (44296,)\n",
            "Done:  Au10_R-BINAP_4_CCPhCF3_c3.xyz shape:  (44296,)\n",
            "Done:  Au10_S4_dppNR1_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au10_S4_dppNR2_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au10_S4_dppNR3_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au10_S4_dppNTol_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au10_S-BINAP_4_CCPhCF3_c3.xyz shape:  (44296,)\n",
            "Done:  Au10_SC4_10_c0.xyz shape:  (44296,)\n",
            "Done:  Au10_Se4_dppNR4_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au10_TBBT_10_c0.xyz shape:  (44296,)\n",
            "Done:  Au10_bylidene_4_Br2_c2.xyz shape:  (44296,)\n",
            "Done:  Au11_PDPE_4_Cl2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_PMePh2_10_C3v_c3.xyz shape:  (44296,)\n",
            "Done:  Au11_PMePh2_10_D4d_c3.xyz shape:  (44296,)\n",
            "Done:  Au11_PNC_6_PPh3_2_c5.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_Br3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_CNPr_2_I_c2.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_Cl3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_I3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_Spyr_3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_7_p-MBA_3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_8_CCPhCF3_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_PPh3_8_Cl2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_PPhCF3_7_Cl3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PPhF3_7_I3_c0.xyz shape:  (44296,)\n",
            "Done:  Au11_PXant_4_Cl2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_bylidene_5_c3.xyz shape:  (44296,)\n",
            "Done:  Au11_dppe_6_c3.xyz shape:  (44296,)\n",
            "Done:  Au11_dppf_4_Br2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_dppf_4_Cl2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_dppf_4_I2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_dppf_4_SCN_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au11_dppp_5_c3.xyz shape:  (44296,)\n",
            "Done:  Au11_dpppen_4_SePh_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au12_SC4_12_c0.xyz shape:  (44296,)\n",
            "Done:  Au13_PMe2Ph_10_Cl2_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_PPh3_8_p-MBA_3_c0.xyz shape:  (44296,)\n",
            "Done:  Au13_SAdm_8_dppb_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au13_SbPh3_8_Cl4_c1.xyz shape:  (44296,)\n",
            "Done:  Au13_bylidene_5_Br2_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_bylidene_5_Cl2_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_bylidene_8_CCPhF_4_c1.xyz shape:  (44296,)\n",
            "Done:  Au13_bylidene_9_Cl3_c2.xyz shape:  (44296,)\n",
            "Done:  Au13_dppe_5_CCPh_2_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_dppe_5_Cl2_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_dppm_6_c3.xyz shape:  (44296,)\n",
            "Done:  Au13_dppm_6_c5.xyz shape:  (44296,)\n",
            "Done:  Au14_SCy_10_dppb_c0.xyz shape:  (44296,)\n",
            "Done:  Au16_SAdm_12_c0.xyz shape:  (44296,)\n",
            "Done:  Au18_S2_STipb_12_c0.xyz shape:  (44296,)\n",
            "Done:  Au18_S8_dppe_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au18_SCy_14_c0.xyz shape:  (44296,)\n",
            "Done:  Au18_dppm_6_Br4_c2.xyz shape:  (44296,)\n",
            "Done:  Au18_dppm_6_Cl4_c4.xyz shape:  (44296,)\n",
            "Done:  Au19_dppNH_3_CCPh_9_c2.xyz shape:  (44296,)\n",
            "Done:  Au20_PP3_4_c4.xyz shape:  (44296,)\n",
            "Done:  Au20_PPhpy2_10_Cl4_c2.xyz shape:  (44296,)\n",
            "Done:  Au20_PTBu3_8_c0.xyz shape:  (44296,)\n",
            "Done:  Au20_TBBT_16_c0.xyz shape:  (44296,)\n",
            "Done:  Au20_dppm_6_CN_6_c0.xyz shape:  (44296,)\n",
            "Done:  Au21_SAdm_15_c0.xyz shape:  (44296,)\n",
            "Done:  Au21_SCy_12_dppm_2_c1.xyz shape:  (44296,)\n",
            "Done:  Au21_STBu_15_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au21_S_SAdm_15_c0.xyz shape:  (44296,)\n",
            "Done:  Au22_CCR_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au22_CCTBu_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au22_SAdm_16_c0.xyz shape:  (44296,)\n",
            "Done:  Au22_dppo_6_c0.xyz shape:  (44296,)\n",
            "Done:  Au23_CCTBu_15_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au23_CCTBu_15_iso2_c0.xyz shape:  (44296,)\n",
            "Done:  Au23_PPh3_6_CCPh_9_c2.xyz shape:  (44296,)\n",
            "Done:  Au23_PPh3_10_dpa_2_Cl_c2.xyz shape:  (44296,)\n",
            "Done:  Au23_SCy_16_c-1.xyz shape:  (44296,)\n",
            "Done:  Au23_bylidene_6_CCPh_9_c2.xyz shape:  (44296,)\n",
            "Done:  Au24_PPh3_4_CCPh_14_c2.xyz shape:  (44296,)\n",
            "Done:  Au24_PPh3_10_PET_5_Br2_c1.xyz shape:  (44296,)\n",
            "Done:  Au24_R-dppb_6_Cl4_c2.xyz shape:  (44296,)\n",
            "Done:  Au24_S-dppb_6_Cl4_c2.xyz shape:  (44296,)\n",
            "Done:  Au24_SAdm_16_c0.xyz shape:  (44296,)\n",
            "Done:  Au24_SCH2Ph_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au24_SPh_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au24_STBu_16_c0.xyz shape:  (44296,)\n",
            "Done:  Au24_SePh_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au24_TBTT_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_CCAr_18_c-1.xyz shape:  (44296,)\n",
            "Done:  Au25_PET-mN3_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_PET-oN3_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_PET-pN3_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_PET_5_PPh3_10_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au25_PET_16_SPhBr_2_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_PET_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_PET_18_c1.xyz shape:  (44296,)\n",
            "Done:  Au25_PET_18_c-1.xyz shape:  (44296,)\n",
            "Done:  Au25_SBu_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_SCy_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_SEt_5_PPh3_10_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au25_SNap_18_c-1.xyz shape:  (44296,)\n",
            "Done:  Au25_SPhF_18_c-1.xyz shape:  (44296,)\n",
            "Done:  Au25_SPh_5_PPh3_10_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au25_SPh_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_SPr_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au25_SePh_5_PPh3_10_Cl2_c1.xyz shape:  (44296,)\n",
            "Done:  Au25_SePh_5_PPh3_10_Cl2_c2.xyz shape:  (44296,)\n",
            "Done:  Au25_bylidene_10_Br7_c2.xyz shape:  (44296,)\n",
            "Done:  Au25_bylidene_10_Br8_c1.xyz shape:  (44296,)\n",
            "Done:  Au28_SCy_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au28_TBBT_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au29_SAdm_19_c0.xyz shape:  (44296,)\n",
            "Done:  Au30_SAdm_18_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au30_SAdm_18_iso2_c0.xyz shape:  (44296,)\n",
            "Done:  Au30_STBu_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au30_S_STBu_18_c0.xyz shape:  (44296,)\n",
            "Done:  Au32_PBu3_12_Cl8_c0.xyz shape:  (44296,)\n",
            "Done:  Au32_PEt3_12_Cl8_c0.xyz shape:  (44296,)\n",
            "Done:  Au32_PPh3_8_dpa_6_c2.xyz shape:  (44296,)\n",
            "Done:  Au32_PPr3_12_Cl8_c0.xyz shape:  (44296,)\n",
            "Done:  Au34_DMBT_22_c0.xyz shape:  (44296,)\n",
            "Done:  Au34_SCy_22_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_CCPh_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_DMBT_24_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_DMBT_24_iso2_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_SCyp_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_SPh_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_STol_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_SePh_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au36_TBBT_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au38_CCPh_20_PPh3_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au38_DMBT_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au38_PET_24_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au38_PET_24_iso2_c0.xyz shape:  (44296,)\n",
            "Done:  Au38_S2_SAdm_20_c0.xyz shape:  (44296,)\n",
            "Done:  Au38_STol_20_PPh3_4_c2.xyz shape:  (44296,)\n",
            "Done:  Au40_SAdm_22_c0.xyz shape:  (44296,)\n",
            "Done:  Au40_STol_24_c0.xyz shape:  (44296,)\n",
            "Done:  Au40_dppm_4_CCPh_20_c4.xyz shape:  (44296,)\n",
            "Done:  Au42_SCH2Ph_32_c0.xyz shape:  (44296,)\n",
            "Done:  Au42_SCy_26_c0.xyz shape:  (44296,)\n",
            "Done:  Au42_TBBT_26_iso1_c0.xyz shape:  (44296,)\n",
            "Done:  Au42_TBBT_26_iso2_c0.xyz shape:  (44296,)\n",
            "Done:  Au43_SCy_25_c0.xyz shape:  (44296,)\n",
            "Done:  Au44_CCPh_28_c0.xyz shape:  (44296,)\n",
            "Done:  Au44_DMBT_26_c0.xyz shape:  (44296,)\n",
            "Done:  Au44_TBBT_26_c0.xyz shape:  (44296,)\n",
            "Done:  Au44_TBBT_28_c0.xyz shape:  (44296,)\n",
            "Done:  Au48_TBBT_28_c0.xyz shape:  (44296,)\n",
            "Done:  Au49_DMBT_27_c0.xyz shape:  (44296,)\n",
            "Done:  Au52_PET_32_c0.xyz shape:  (44296,)\n",
            "Done:  Au52_TBBT_32_c0.xyz shape:  (44296,)\n",
            "Done:  Au54_PEt3_18_Cl12_c0.xyz shape:  (44296,)\n",
            "Done:  Au56_TBBT_34_c0.xyz shape:  (44296,)\n",
            "Done:  Au60_S6_SCH2Ph_36_c0.xyz shape:  (44296,)\n",
            "Done:  Au60_S7_SCH2Ph_36_c0.xyz shape:  (44296,)\n",
            "Done:  Au67_CCR_32_Cl4_c-3.xyz shape:  (44296,)\n",
            "Done:  Au67_SCH2Ph_35_c0.xyz shape:  (44296,)\n",
            "Done:  Au70_S20_PPh3_12_c0.xyz shape:  (44296,)\n",
            "Done:  Au92_TBBT_44_c0.xyz shape:  (44296,)\n",
            "Done:  Au103_S2_SNap_41_c0.xyz shape:  (44296,)\n",
            "Done:  Au108_S24_PPh3_16_c0.xyz shape:  (44296,)\n",
            "Done:  Au110_CCPhCF3_48_c-2.xyz shape:  (44296,)\n",
            "Done:  Au133_TBBT_52_c0.xyz shape:  (44296,)\n",
            "Done:  Au144_PET_60_c0.xyz shape:  (44296,)\n",
            "Done:  Au_PPh3_CH3_c0.xyz shape:  (44296,)\n",
            "Done:  Au_SbPh3_4_c0.xyz shape:  (44296,)\n",
            "Done:  Au_SbPh3_Cl_c0.xyz shape:  (44296,)\n",
            "Done:  Au_SbTol3_3_SbCl2Tol2_c0.xyz shape:  (44296,)\n",
            "error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "rziN2BWXwncJ",
        "outputId": "e73606a3-8ee4-4f48-eab7-844893386e03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-740eec0d-951d-42cf-8050-a56b8961525c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>names</th>\n",
              "      <th>imag+zpve</th>\n",
              "      <th>u298</th>\n",
              "      <th>h298</th>\n",
              "      <th>g298</th>\n",
              "      <th>gap</th>\n",
              "      <th>dipX</th>\n",
              "      <th>dipY</th>\n",
              "      <th>dipZ</th>\n",
              "      <th>dipTotal</th>\n",
              "      <th>core</th>\n",
              "      <th>Tetrahedral_count</th>\n",
              "      <th>Unconnected_triangles_count</th>\n",
              "      <th>Triangles_with_1_shared_vertex_count</th>\n",
              "      <th>Triangles_with_2_shared_vertices_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AuTM-1.xyz.1315600.hpc-mn1.out</td>\n",
              "      <td>-4.54      9.35       0.361254792113</td>\n",
              "      <td>-126.516193</td>\n",
              "      <td>-126.114631</td>\n",
              "      <td>-126.226368</td>\n",
              "      <td>1.947794</td>\n",
              "      <td>-1.8152</td>\n",
              "      <td>2.4689</td>\n",
              "      <td>-3.5907</td>\n",
              "      <td>11.998</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AuTM-2.xyz.1315601.hpc-mn1.out</td>\n",
              "      <td>5.26       5.70       0.300816191820</td>\n",
              "      <td>-75.059447</td>\n",
              "      <td>-74.731351</td>\n",
              "      <td>-74.816078</td>\n",
              "      <td>0.536785</td>\n",
              "      <td>1.7070</td>\n",
              "      <td>-12.6958</td>\n",
              "      <td>-6.9454</td>\n",
              "      <td>37.038</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AuTM-3.xyz.1315602.hpc-mn1.out</td>\n",
              "      <td>5.72       7.27       0.414537168724</td>\n",
              "      <td>-220.342502</td>\n",
              "      <td>-219.860514</td>\n",
              "      <td>-220.026097</td>\n",
              "      <td>1.281813</td>\n",
              "      <td>1.0570</td>\n",
              "      <td>0.0231</td>\n",
              "      <td>-1.4388</td>\n",
              "      <td>4.538</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AuTM-4.xyz.1315603.hpc-mn1.out</td>\n",
              "      <td>11.56      27.95      0.330145801891</td>\n",
              "      <td>-78.203268</td>\n",
              "      <td>-77.844378</td>\n",
              "      <td>-77.931539</td>\n",
              "      <td>2.252962</td>\n",
              "      <td>6.8291</td>\n",
              "      <td>3.2187</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>19.189</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AuTM-5.xyz.1315604.hpc-mn1.out</td>\n",
              "      <td>1.77       38.84      0.244731836526</td>\n",
              "      <td>-32.384417</td>\n",
              "      <td>-32.124641</td>\n",
              "      <td>-32.182588</td>\n",
              "      <td>4.939549</td>\n",
              "      <td>1.6536</td>\n",
              "      <td>9.0627</td>\n",
              "      <td>20.8189</td>\n",
              "      <td>57.866</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3154</th>\n",
              "      <td>AuTM-3155.xyz.1323291.hpc-mn1.out</td>\n",
              "      <td>14.72      21.95      0.405623835398</td>\n",
              "      <td>-85.628117</td>\n",
              "      <td>-85.190559</td>\n",
              "      <td>-85.282873</td>\n",
              "      <td>2.599206</td>\n",
              "      <td>3.8788</td>\n",
              "      <td>3.9315</td>\n",
              "      <td>1.8642</td>\n",
              "      <td>14.816</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3155</th>\n",
              "      <td>AuTM-3156.xyz.1323292.hpc-mn1.out</td>\n",
              "      <td>7.50       11.77      0.300199763344</td>\n",
              "      <td>-56.400818</td>\n",
              "      <td>-56.077525</td>\n",
              "      <td>-56.153166</td>\n",
              "      <td>1.946276</td>\n",
              "      <td>-0.4391</td>\n",
              "      <td>2.4436</td>\n",
              "      <td>-1.3932</td>\n",
              "      <td>7.236</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3156</th>\n",
              "      <td>AuTM-3157.xyz.1323293.hpc-mn1.out</td>\n",
              "      <td>9.52       16.36      0.262733823975</td>\n",
              "      <td>-56.829549</td>\n",
              "      <td>-56.543338</td>\n",
              "      <td>-56.620601</td>\n",
              "      <td>3.519847</td>\n",
              "      <td>0.2095</td>\n",
              "      <td>3.4129</td>\n",
              "      <td>-1.9723</td>\n",
              "      <td>10.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3157</th>\n",
              "      <td>AuTM-3158.xyz.1323294.hpc-mn1.out</td>\n",
              "      <td>7.27       8.38       1.048572866833</td>\n",
              "      <td>-198.407509</td>\n",
              "      <td>-197.277608</td>\n",
              "      <td>-197.473715</td>\n",
              "      <td>1.877934</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.1856</td>\n",
              "      <td>-1.2711</td>\n",
              "      <td>3.680</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158</th>\n",
              "      <td>AuTM-3159.xyz.1323295.hpc-mn1.out</td>\n",
              "      <td>4.90       5.90       1.261562859735</td>\n",
              "      <td>-226.946163</td>\n",
              "      <td>-225.583462</td>\n",
              "      <td>-225.823290</td>\n",
              "      <td>3.277171</td>\n",
              "      <td>-0.6295</td>\n",
              "      <td>-2.4385</td>\n",
              "      <td>1.0070</td>\n",
              "      <td>6.894</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3159 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-740eec0d-951d-42cf-8050-a56b8961525c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-740eec0d-951d-42cf-8050-a56b8961525c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-740eec0d-951d-42cf-8050-a56b8961525c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                   names  \\\n",
              "0        AuTM-1.xyz.1315600.hpc-mn1.out    \n",
              "1        AuTM-2.xyz.1315601.hpc-mn1.out    \n",
              "2        AuTM-3.xyz.1315602.hpc-mn1.out    \n",
              "3        AuTM-4.xyz.1315603.hpc-mn1.out    \n",
              "4        AuTM-5.xyz.1315604.hpc-mn1.out    \n",
              "...                                  ...   \n",
              "3154  AuTM-3155.xyz.1323291.hpc-mn1.out    \n",
              "3155  AuTM-3156.xyz.1323292.hpc-mn1.out    \n",
              "3156  AuTM-3157.xyz.1323293.hpc-mn1.out    \n",
              "3157  AuTM-3158.xyz.1323294.hpc-mn1.out    \n",
              "3158  AuTM-3159.xyz.1323295.hpc-mn1.out    \n",
              "\n",
              "                                   imag+zpve        u298        h298  \\\n",
              "0      -4.54      9.35       0.361254792113  -126.516193 -126.114631   \n",
              "1      5.26       5.70       0.300816191820   -75.059447  -74.731351   \n",
              "2      5.72       7.27       0.414537168724  -220.342502 -219.860514   \n",
              "3      11.56      27.95      0.330145801891   -78.203268  -77.844378   \n",
              "4      1.77       38.84      0.244731836526   -32.384417  -32.124641   \n",
              "...                                      ...         ...         ...   \n",
              "3154   14.72      21.95      0.405623835398   -85.628117  -85.190559   \n",
              "3155   7.50       11.77      0.300199763344   -56.400818  -56.077525   \n",
              "3156   9.52       16.36      0.262733823975   -56.829549  -56.543338   \n",
              "3157   7.27       8.38       1.048572866833  -198.407509 -197.277608   \n",
              "3158   4.90       5.90       1.261562859735  -226.946163 -225.583462   \n",
              "\n",
              "            g298       gap    dipX     dipY     dipZ  dipTotal  core  \\\n",
              "0    -126.226368  1.947794 -1.8152   2.4689  -3.5907    11.998     1   \n",
              "1     -74.816078  0.536785  1.7070 -12.6958  -6.9454    37.038     1   \n",
              "2    -220.026097  1.281813  1.0570   0.0231  -1.4388     4.538     1   \n",
              "3     -77.931539  2.252962  6.8291   3.2187   0.0003    19.189     1   \n",
              "4     -32.182588  4.939549  1.6536   9.0627  20.8189    57.866     1   \n",
              "...          ...       ...     ...      ...      ...       ...   ...   \n",
              "3154  -85.282873  2.599206  3.8788   3.9315   1.8642    14.816     1   \n",
              "3155  -56.153166  1.946276 -0.4391   2.4436  -1.3932     7.236     1   \n",
              "3156  -56.620601  3.519847  0.2095   3.4129  -1.9723    10.033     1   \n",
              "3157 -197.473715  1.877934  0.6674  -0.1856  -1.2711     3.680     1   \n",
              "3158 -225.823290  3.277171 -0.6295  -2.4385   1.0070     6.894     1   \n",
              "\n",
              "      Tetrahedral_count  Unconnected_triangles_count  \\\n",
              "0                     0                            0   \n",
              "1                     0                            0   \n",
              "2                     0                            0   \n",
              "3                     0                            0   \n",
              "4                     0                            0   \n",
              "...                 ...                          ...   \n",
              "3154                  0                            0   \n",
              "3155                  0                            0   \n",
              "3156                  0                            0   \n",
              "3157                  0                            0   \n",
              "3158                  0                            0   \n",
              "\n",
              "      Triangles_with_1_shared_vertex_count  \\\n",
              "0                                        0   \n",
              "1                                        0   \n",
              "2                                        0   \n",
              "3                                        0   \n",
              "4                                        0   \n",
              "...                                    ...   \n",
              "3154                                     0   \n",
              "3155                                     0   \n",
              "3156                                     0   \n",
              "3157                                     0   \n",
              "3158                                     0   \n",
              "\n",
              "      Triangles_with_2_shared_vertices_count  \n",
              "0                                          0  \n",
              "1                                          0  \n",
              "2                                          0  \n",
              "3                                          0  \n",
              "4                                          0  \n",
              "...                                      ...  \n",
              "3154                                       0  \n",
              "3155                                       0  \n",
              "3156                                       0  \n",
              "3157                                       0  \n",
              "3158                                       0  \n",
              "\n",
              "[3159 rows x 15 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "DatabaseTM16Jan includes the XTB calculated properties for the AuTM molecules, along with their simplex counts already calculated at 4.0 filter via the function above\n",
        "\"\"\"\n",
        "\n",
        "DatasetTM = pd.read_csv(\"./data/AuTM/DatasetAuTM.csv\",\n",
        "                  sep=',',\n",
        "                  header = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R5PX6CcoOZp"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Appending xyz texts of AuTMs to dataframe\n",
        "\"\"\"\n",
        "os.chdir(\"./data/AuTM/AuTM_xyz_files\")\n",
        "xyz_list = []\n",
        "files = []\n",
        "for i in range(len(DatasetTM)):\n",
        "  print(\"Datapoint: \",i)\n",
        "  filename = \"AuTM-\" + str(i+1) + \".xyz\"\n",
        "  with open(filename) as f:\n",
        "      lines = f.readlines()\n",
        "      files.append(filename)\n",
        "      xyz_list.append(lines)\n",
        "\n",
        "DatasetTM[\"xyz\"]=xyz_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS-kt-1FvwCD"
      },
      "outputs": [],
      "source": [
        "#Persistence Image Parameters\n",
        "resolution=100\n",
        "myspread=0.3\n",
        "min_bound=-0.3\n",
        "max_bound=7\n",
        "electroneg_addition=+0.4\n",
        "electroneg_division=10\n",
        "B1_buffer=0.5\n",
        "B2_buffer=0.05\n",
        "\n",
        "append_persistence_image(DatasetAuTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA8sidF0mGw7"
      },
      "source": [
        "# Read from pre-calculated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgGD26OnmTv2"
      },
      "outputs": [],
      "source": [
        "DatasetAuNC = pd.read_pickle('./data/AuNC/DatasetAuNC.pkl')\n",
        "DatasetTM = pd.read_pickle('./data/AuTM/DatasetAuTM.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J82C1fy_PFD"
      },
      "source": [
        "## Result plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcVVD96c6KT6"
      },
      "outputs": [],
      "source": [
        "def analyze_regression_performance(true_values, predicted_values, parameters, duration, text_position='top_left', save_image=False, image_name=\"regression_performance.png\"):\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(true_values, predicted_values)\n",
        "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
        "    r2 = r2_score(true_values, predicted_values)\n",
        "\n",
        "    # Create a blank figure for text-only display\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.axis('off')  # Turn off axis for text display only\n",
        "\n",
        "    # Determine text position\n",
        "    if text_position == 'top_left':\n",
        "        text_x, text_y = 0.02, 0.98\n",
        "        ha, va = 'left', 'top'\n",
        "    elif text_position == 'top_right':\n",
        "        text_x, text_y = 0.98, 0.98\n",
        "        ha, va = 'right', 'top'\n",
        "    else:\n",
        "        raise ValueError(\"Invalid text_position. Choose 'top_left' or 'top_right'.\")\n",
        "\n",
        "    # Add text with model parameters and evaluation metrics\n",
        "    parameters_text = '\\n'.join(f'{key}: {value}' for key, value in parameters.items())\n",
        "    metrics_text = f\"Mean Absolute Error (MAE): {mae:.4f}\\n\" \\\n",
        "                   f\"Root Mean Squared Error (RMSE): {rmse:.4f}\\n\" \\\n",
        "                   f\"R-squared (R²): {r2:.4f}\\n\" \\\n",
        "                   f\"Training duration (s): {duration:.1f}\\n\"\n",
        "    text = f\"{parameters_text}\\n\\n{metrics_text}\"\n",
        "    ax.text(text_x, text_y, text, transform=ax.transAxes,\n",
        "            bbox=dict(facecolor='white', edgecolor='black', alpha=0.8),\n",
        "            horizontalalignment=ha, verticalalignment=va)\n",
        "\n",
        "    if save_image:\n",
        "        plt.savefig(image_name, bbox_inches='tight')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFoUzP3B6LnN"
      },
      "outputs": [],
      "source": [
        "def plot_ML_results(true_values, predicted_values, x_tick_sep=1.0, y_tick_sep=1.0, dpi=900, save_image=False, image_name=\"plot_ML_results.png\"):\n",
        "    \"\"\"\n",
        "    Plot the true values against predicted values for machine learning model evaluation.\n",
        "\n",
        "    Parameters:\n",
        "        true_values (array-like): True target values.\n",
        "        predicted_values (array-like): Predicted target values.\n",
        "        x_tick_sep (float): Separation between x-axis tick marks. Default is 1.0.\n",
        "        y_tick_sep (float): Separation between y-axis tick marks. Default is 1.0.\n",
        "        dpi (int): Dots per inch for the image resolution. Default is 900.\n",
        "        save_image (bool): If True, save the image. Default is False.\n",
        "        image_name (str): Name of the saved image file. Default is \"plot_ML_results.png\".\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(true_values, predicted_values, c='teal', s=40)\n",
        "\n",
        "    max_value = max(max(predicted_values), max(true_values))\n",
        "    min_value = min(min(predicted_values), min(true_values))\n",
        "\n",
        "    # Ensure the axes always start at 0.0\n",
        "    max_value = max(max_value, 0.0)\n",
        "    min_value = min(min_value, 0.0)\n",
        "\n",
        "    plt.plot([min_value, max_value], [min_value, max_value], 'black')\n",
        "\n",
        "    plt.xlabel('Calculated HOMO-LUMO gap (eV)', fontsize=25)\n",
        "    plt.ylabel('Predicted HOMO-LUMO gap (eV)', fontsize=25)\n",
        "\n",
        "    plt.tick_params(axis='both', labelsize=20, pad=8)\n",
        "    x_ticks = np.arange(int(np.floor(min_value)), int(np.ceil(max_value)) + 1, x_tick_sep)\n",
        "    y_ticks = np.arange(int(np.floor(min_value)), int(np.ceil(max_value)) + 1, y_tick_sep)\n",
        "\n",
        "    plt.xticks(x_ticks)\n",
        "    plt.yticks(y_ticks)\n",
        "\n",
        "    plt.axis('equal')\n",
        "\n",
        "    if save_image:\n",
        "        plt.savefig(image_name, dpi=dpi)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have 'true_values' and 'predicted_values' arrays containing the data.\n",
        "# plot_ML_results(true_values, predicted_values, x_tick_sep=0.5, y_tick_sep=0.5, dpi=900, save_image=True, image_name=\"my_plot.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnucUzOaGOMG"
      },
      "source": [
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(use_simplex=True, use_charge=True):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Define the input layers\n",
        "    input_1 = Input(shape=(5,))\n",
        "    input_2 = Input(shape=(100, 100, 1))\n",
        "    input_3 = Input(shape=(1,))\n",
        "\n",
        "    # Model 1 - Simplexes\n",
        "    if use_simplex:\n",
        "        dense_1 = Dense(5, activation='relu')(input_1)\n",
        "        dense_1_extra = Dense(3, activation='relu')(dense_1)\n",
        "        input_concat = [dense_1_extra]\n",
        "    else:\n",
        "        input_concat = []\n",
        "\n",
        "    # Model 2 - Convolutional Neural Network\n",
        "    conv_1 = Conv2D(16, (3, 3), activation='relu')(input_2)\n",
        "    maxpool_1 = MaxPooling2D((2, 2))(conv_1)\n",
        "    conv_2 = Conv2D(16, (3, 3), activation='relu')(maxpool_1)\n",
        "    maxpool_2 = MaxPooling2D((2, 2))(conv_2)\n",
        "    flatten = Flatten()(maxpool_2)\n",
        "    dense_2 = Dense(32, activation='relu')(flatten)\n",
        "    dense_3 = Dense(16, activation='relu')(dense_2)\n",
        "    input_concat.append(dense_3)\n",
        "\n",
        "    # Model 3 - Charge\n",
        "    if use_charge:\n",
        "        input_concat.append(input_3)\n",
        "\n",
        "    # Concatenate input layers based on whether simplex and/or charge are used\n",
        "    if len(input_concat) > 1:\n",
        "        x = Concatenate()(input_concat)\n",
        "    else:\n",
        "        x = input_concat[0]\n",
        "\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=[input_1, input_2, input_3], outputs=output)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_cnn_leave_one_out(Dataset, sample_size, target_variable, batch_size, learning_rate, patience, model_save_name, use_simplex=True, use_charge=True, random_state=None):\n",
        "    random.seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "    tf.random.set_seed(random_state)\n",
        "\n",
        "    # Initialize the lists for input data and target variable\n",
        "    x1, x2, x3, y = [], [], [], []\n",
        "\n",
        "    # Append data to the lists\n",
        "    for i in range(len(Dataset)):\n",
        "        x1.append(np.asarray([Dataset[\"core\"][i],\n",
        "                              Dataset[\"Tetrahedral_count\"][i],\n",
        "                              Dataset[\"Unconnected_triangles_count\"][i],\n",
        "                              Dataset[\"Triangles_with_1_shared_vertex_count\"][i],\n",
        "                              Dataset[\"Triangles_with_2_shared_vertices_count\"][i]]))\n",
        "\n",
        "        x2.append(np.asarray(Dataset[\"PersImg\"][i]).reshape(100, 100, 1))\n",
        "        x3.append([Dataset[\"Charge\"][i]])\n",
        "        y.append(float(Dataset[\"gap\"][i]))\n",
        "\n",
        "    y = np.array(y)\n",
        "    x1 = np.array(x1)\n",
        "    x2 = np.array(x2)\n",
        "    x3 = np.array(x3)\n",
        "\n",
        "    predicted_arr = []\n",
        "    true_arr = []\n",
        "    MAE_arr = []\n",
        "    RMSE_arr = []\n",
        "    TotalAccuracy = 0\n",
        "    TotalError = 0\n",
        "    MSE = 0\n",
        "\n",
        "    x1_train_full = x1.tolist()\n",
        "    x2_train_full = x2.tolist()\n",
        "    x3_train_full = x3.tolist()\n",
        "    y_train_full = y.tolist()\n",
        "\n",
        "    for test_index in range(len(x1)):\n",
        "        print(\"Cycle: \", test_index)\n",
        "\n",
        "        x1_train = deepcopy(x1_train_full)\n",
        "        x2_train = deepcopy(x2_train_full)\n",
        "        x3_train = deepcopy(x3_train_full)\n",
        "        y_train = deepcopy(y_train_full)\n",
        "\n",
        "        x1_test = x1[test_index]\n",
        "        x2_test = x2[test_index]\n",
        "        x3_test = x3[test_index]\n",
        "        y_test = y[test_index]\n",
        "\n",
        "        x1_train.pop(test_index)\n",
        "        x2_train.pop(test_index)\n",
        "        x3_train.pop(test_index)\n",
        "        y_train.pop(test_index)\n",
        "\n",
        "        x1_train = np.asarray(x1_train)\n",
        "        x2_train = np.asarray(x2_train)\n",
        "        x3_train = np.asarray(x3_train)\n",
        "        y_train = np.asarray(y_train)\n",
        "\n",
        "\n",
        "        # Split training data into train and validation sets\n",
        "        x1_train, x1_val, x2_train, x2_val, x3_train, x3_val, y_train, y_val = train_test_split(\n",
        "            x1_train, x2_train, x3_train, y_train, test_size=10, random_state=random_state)\n",
        "\n",
        "        print(\"start compiling\")\n",
        "\n",
        "        model = create_model(use_simplex=use_simplex, use_charge=use_charge)\n",
        "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                      loss='mean_absolute_error',\n",
        "                      metrics=['mean_squared_error'])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
        "        model_checkpoint = ModelCheckpoint(filepath=model_save_name,\n",
        "                                           save_best_only=True,\n",
        "                                           save_weights_only=False,\n",
        "                                           monitor='val_loss',\n",
        "                                           mode='min',\n",
        "                                           verbose=1)\n",
        "\n",
        "        start_time = time.time()  # Start the timer\n",
        "        print(\"start fitting\")\n",
        "        model.fit([x1_train, x2_train, x3_train],\n",
        "                  y_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=500,\n",
        "                  verbose=1,\n",
        "                  validation_data=([x1_val, x2_val, x3_val], y_val),\n",
        "                  callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        end_time = time.time()  # Stop the timer\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        model = load_model(model_save_name)\n",
        "\n",
        "        y_pred = model.predict([np.asarray([x1_test]), np.asarray([x2_test]), np.asarray([x3_test])])\n",
        "        predicted_arr.append(y_pred)\n",
        "        true_arr.append(float(y_test))\n",
        "\n",
        "    return predicted_arr, true_arr, duration\n"
      ],
      "metadata": {
        "id": "HLN20pVS9pGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/AuNC database/fig4_plots\")\n",
        "\n",
        "target_variable = \"gap\"\n",
        "batch_size = 24\n",
        "learning_rate=0.001\n",
        "patience = 40\n",
        "Filename = \"CNN\" + \"_\" + target_variable\n",
        "seed = 42\n",
        "model_save_name = \"best_cnn_gap.h5\"\n",
        "if target_variable == \"u298\": tick_sep=150\n",
        "elif target_variable == \"gap\": tick_sep=0.5\n",
        "else: tick_sep=50\n",
        "\n",
        "parameters = {'target_variable': target_variable, 'batch_size': batch_size, \"lr\": learning_rate, \"seed\": seed}\n",
        "\n",
        "predicted_values, true_values, duration = run_cnn_leave_one_out(Dataset=DatasetAuNC,\n",
        "                                                                sample_size=len(DatasetAuNC),\n",
        "                                                                target_variable=target_variable,\n",
        "                                                                batch_size=batch_size, learning_rate=learning_rate, patience=patience,\n",
        "                                                                model_save_name=model_save_name,\n",
        "                                                                random_state=seed,\n",
        "                                                                use_simplex=True, use_charge=True,\n",
        "                                                                )\n",
        "analyze_regression_performance(true_values, predicted_values, parameters, duration, save_image=False, image_name=Filename+\"_data.png\")\n",
        "plot_ML_results(true_values, predicted_values, x_tick_sep=tick_sep, y_tick_sep=tick_sep, save_image=False, image_name=Filename+\".pdf\")"
      ],
      "metadata": {
        "id": "RWZJkXicAMIr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PGcP4hneFh24",
        "2J82C1fy_PFD",
        "Cth4q9IM6NDl",
        "KHBecwB0_2_I",
        "khEOzNYf40co"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}